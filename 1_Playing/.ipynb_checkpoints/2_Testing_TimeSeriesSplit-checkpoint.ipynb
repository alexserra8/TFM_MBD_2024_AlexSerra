{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\alexs\\Documents\\TFM_MBD\\TFM_MBD_2024_AlexSerra\\preprocessed_data\\other_europe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim = int(df.shape[0]*0.7)\n",
    "df_train = df.iloc[:train_lim]\n",
    "df_test = df.iloc[train_lim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lim_meta = int(df_train.shape[0]*0.6)\n",
    "df_train_meta = df_train.iloc[:train_lim_meta]\n",
    "df_validation_meta = df_train.iloc[train_lim_meta:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define general datasets:\n",
    "\n",
    "- df_train --> data that we are going to use to train our algorithms (prophet, autoarima, ....)\n",
    "- df_test --> data that only will be used to evaluate scores of how the algorithm work.\n",
    "\n",
    "Now, we also defined \"meta\" dataset. This data will be used to train the meta learner:\n",
    "\n",
    "- df_train_meta --> son algorithm (prophet, autoarima,...) will be trained with this reduced amount of the train dataset.\n",
    "- df_validation_meta --> this data will be used, after having son algorithms trained, to train the meta learner. For example, for a linear regression, it will be used to obtain the coefficients.\n",
    "\n",
    "Once we have the metalearner trained, son algorithms will be trained with full df_train. And then using the metalearner to obtain final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prophet = Prophet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x21bdd116340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prophet.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_prophet = model_prophet.predict(df_test[[\"ds\"]])[\"yhat\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions[\"ds\"] = df_test[\"ds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions [\"prophet\"] = forecast_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(actual, predicted):\n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 21.35%\n"
     ]
    }
   ],
   "source": [
    "mape=calculate_mape(df_test[\"y\"],forecast_prophet)\n",
    "\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_predictions(df_tr, df_te):\n",
    "    # df_tr should contain ds and y columns\n",
    "    # df_te should contain ds column.\n",
    "    m = Prophet()\n",
    "    m.fit(df_tr)\n",
    "    fore = m.predict(df_te[[\"ds\"]])[\"yhat\"].values\n",
    "    return fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prophet adding regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prophet_multiva = Prophet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in df_train.columns[2:]:\n",
    "    model_prophet_multiva.add_regressor(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x21bdd3c2190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prophet_multiva.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_prophet_multiva = model_prophet_multiva.predict(df_test.drop(columns=\"y\"))[\"yhat\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 21.87%\n"
     ]
    }
   ],
   "source": [
    "mape=calculate_mape(df_test[\"y\"],forecast_prophet_multiva)\n",
    "\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions[\"prophet_multiva\"] = forecast_prophet_multiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prophet_predictions_multiva(df_tr, df_te):\n",
    "    # df_tr should contain ds and y columns\n",
    "    # df_te should contain ds column.\n",
    "    m = Prophet()\n",
    "    for e in df_tr.columns[2:]:\n",
    "        m.add_regressor(e)\n",
    "    m.fit(df_tr)\n",
    "    fore = m.predict(df_te.drop(columns=\"y\"))[\"yhat\"].values\n",
    "    return fore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Autoarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_arima = df_train.copy()\n",
    "df_test_arima = df_test.copy()\n",
    "\n",
    "df_train_arima.set_index('ds', inplace=True)\n",
    "df_train_arima = df_train_arima[[\"y\"]]\n",
    "\n",
    "df_test_arima.set_index('ds', inplace=True)\n",
    "df_test_arima = df_test_arima[[\"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(0,0,0)[0] intercept   : AIC=268.565, Time=0.13 sec\n",
      " ARIMA(0,0,0)(0,0,0)[0] intercept   : AIC=325.069, Time=0.03 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0] intercept   : AIC=278.007, Time=0.05 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0] intercept   : AIC=292.544, Time=0.04 sec\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=646.754, Time=0.01 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0] intercept   : AIC=267.768, Time=0.10 sec\n",
      " ARIMA(0,0,2)(0,0,0)[0] intercept   : AIC=290.754, Time=0.06 sec\n",
      " ARIMA(1,0,1)(0,0,0)[0] intercept   : AIC=265.856, Time=0.09 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0] intercept   : AIC=267.825, Time=0.20 sec\n",
      " ARIMA(2,0,0)(0,0,0)[0] intercept   : AIC=274.014, Time=0.09 sec\n",
      " ARIMA(1,0,1)(0,0,0)[0]             : AIC=272.651, Time=0.06 sec\n",
      "\n",
      "Best model:  ARIMA(1,0,1)(0,0,0)[0] intercept\n",
      "Total fit time: 0.896 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  128\n",
      "Model:               SARIMAX(1, 0, 1)   Log Likelihood                -128.928\n",
      "Date:                Tue, 21 May 2024   AIC                            265.856\n",
      "Time:                        16:13:12   BIC                            277.264\n",
      "Sample:                    01-06-2020   HQIC                           270.491\n",
      "                         - 06-13-2022                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.3084      0.154      1.997      0.046       0.006       0.611\n",
      "ar.L1          0.8938      0.053     16.859      0.000       0.790       0.998\n",
      "ma.L1         -0.5344      0.106     -5.021      0.000      -0.743      -0.326\n",
      "sigma2         0.4367      0.060      7.292      0.000       0.319       0.554\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):                 0.60\n",
      "Prob(Q):                              0.92   Prob(JB):                         0.74\n",
      "Heteroskedasticity (H):               0.80   Skew:                            -0.03\n",
      "Prob(H) (two-sided):                  0.47   Kurtosis:                         2.67\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# Train AutoARIMA model\n",
    "model_autoarima = auto_arima(df_train_arima, \n",
    "                   seasonal=True,  # Change to True if you want to fit a seasonal ARIMA\n",
    "\n",
    "                   stepwise=True,   # Set to False to perform a more exhaustive search\n",
    "                   trace=True)      # Set to True to see the search progress\n",
    "\n",
    "# Print the best model parameters\n",
    "print(model_autoarima.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_autoarima = model_autoarima.predict(n_periods=df_test_arima.shape[0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_predictions[\"autoarima\"] = forecast_autoarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 21.07%\n"
     ]
    }
   ],
   "source": [
    "mape=calculate_mape(df_test[\"y\"],forecast_autoarima)\n",
    "\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoarima_predictions(df_tr, df_te):\n",
    "    df_tr1=df_tr.copy()\n",
    "    df_tr1.set_index('ds', inplace=True)\n",
    "    df_tr1 = df_tr1[[\"y\"]]\n",
    "    \n",
    "    df_te1 = df_te.copy()\n",
    "    df_te1.set_index('ds', inplace=True)\n",
    "    df_te1 = df_te1[[\"y\"]]\n",
    "    \n",
    "    m_autoarima = auto_arima(df_tr1, \n",
    "                   seasonal=True,  # Change to True if you want to fit a seasonal ARIMA\n",
    "\n",
    "                   stepwise=True,   # Set to False to perform a more exhaustive search\n",
    "                   trace=False)      # Set to True to see the search progress\n",
    "    \n",
    "    fore = m_autoarima.predict(n_periods=df_te1.shape[0]).values\n",
    "    return fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Trying Timeseries test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temp</th>\n",
       "      <th>gtrends_allergie</th>\n",
       "      <th>gtrends_pollen allergie</th>\n",
       "      <th>gtrends_heuschnupfen</th>\n",
       "      <th>gtrends_pollen</th>\n",
       "      <th>influenza</th>\n",
       "      <th>pollution_Zurich_no2</th>\n",
       "      <th>pollution_Zurich_o3</th>\n",
       "      <th>pollution_Zurich_pm10</th>\n",
       "      <th>pollution_Zurich_pm25</th>\n",
       "      <th>pollution_Zurich_so2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>3.506025</td>\n",
       "      <td>81.875606</td>\n",
       "      <td>274.946388</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>221.0</td>\n",
       "      <td>13.942857</td>\n",
       "      <td>5.657143</td>\n",
       "      <td>15.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>3.898515</td>\n",
       "      <td>77.805608</td>\n",
       "      <td>275.982323</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.328571</td>\n",
       "      <td>5.485714</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>4.174013</td>\n",
       "      <td>73.820989</td>\n",
       "      <td>275.575986</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>530.5</td>\n",
       "      <td>14.828571</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>3.568473</td>\n",
       "      <td>80.112456</td>\n",
       "      <td>274.589907</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>911.5</td>\n",
       "      <td>18.314286</td>\n",
       "      <td>2.685714</td>\n",
       "      <td>24.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>3.507797</td>\n",
       "      <td>79.792778</td>\n",
       "      <td>279.608504</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>772.0</td>\n",
       "      <td>6.985714</td>\n",
       "      <td>20.357143</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>1.877216</td>\n",
       "      <td>65.656746</td>\n",
       "      <td>292.554001</td>\n",
       "      <td>130</td>\n",
       "      <td>160</td>\n",
       "      <td>210</td>\n",
       "      <td>441</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.242857</td>\n",
       "      <td>28.657143</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>2.989111</td>\n",
       "      <td>63.478175</td>\n",
       "      <td>294.610013</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>232</td>\n",
       "      <td>326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.014286</td>\n",
       "      <td>28.842857</td>\n",
       "      <td>13.428571</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.314286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>3.002538</td>\n",
       "      <td>64.182540</td>\n",
       "      <td>289.707639</td>\n",
       "      <td>123</td>\n",
       "      <td>43</td>\n",
       "      <td>179</td>\n",
       "      <td>195</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.385714</td>\n",
       "      <td>28.628571</td>\n",
       "      <td>7.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>2.186763</td>\n",
       "      <td>74.434524</td>\n",
       "      <td>292.106534</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>23.842857</td>\n",
       "      <td>11.714286</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>0.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>2.412533</td>\n",
       "      <td>63.375661</td>\n",
       "      <td>292.088763</td>\n",
       "      <td>112</td>\n",
       "      <td>29</td>\n",
       "      <td>132</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.928571</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.242857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds         y   humidity        temp  gtrends_allergie  \\\n",
       "0    2020-01-06  3.506025  81.875606  274.946388               115   \n",
       "1    2020-01-13  3.898515  77.805608  275.982323               176   \n",
       "2    2020-01-20  4.174013  73.820989  275.575986               140   \n",
       "3    2020-01-27  3.568473  80.112456  274.589907               150   \n",
       "4    2020-02-03  3.507797  79.792778  279.608504                98   \n",
       "..          ...       ...        ...         ...               ...   \n",
       "123  2022-05-16  1.877216  65.656746  292.554001               130   \n",
       "124  2022-05-23  2.989111  63.478175  294.610013               134   \n",
       "125  2022-05-30  3.002538  64.182540  289.707639               123   \n",
       "126  2022-06-06  2.186763  74.434524  292.106534               151   \n",
       "127  2022-06-13  2.412533  63.375661  292.088763               112   \n",
       "\n",
       "     gtrends_pollen allergie  gtrends_heuschnupfen  gtrends_pollen  influenza  \\\n",
       "0                          0                     8              22      221.0   \n",
       "1                          0                    36              39        3.0   \n",
       "2                          0                     5              27      530.5   \n",
       "3                          0                     5              83      911.5   \n",
       "4                          0                    32              10      772.0   \n",
       "..                       ...                   ...             ...        ...   \n",
       "123                      160                   210             441       17.0   \n",
       "124                      173                   232             326        0.0   \n",
       "125                       43                   179             195       10.0   \n",
       "126                       11                    70             130        0.0   \n",
       "127                       29                   132              99        1.0   \n",
       "\n",
       "     pollution_Zurich_no2  pollution_Zurich_o3  pollution_Zurich_pm10  \\\n",
       "0               13.942857             5.657143              15.428571   \n",
       "1               16.328571             5.485714              12.285714   \n",
       "2               14.828571            11.000000              10.714286   \n",
       "3               18.314286             2.685714              24.142857   \n",
       "4                6.985714            20.357143               6.428571   \n",
       "..                    ...                  ...                    ...   \n",
       "123              5.242857            28.657143              13.571429   \n",
       "124              5.014286            28.842857              13.428571   \n",
       "125              3.385714            28.628571               7.857143   \n",
       "126              4.800000            23.842857              11.714286   \n",
       "127              4.000000            24.928571               8.142857   \n",
       "\n",
       "     pollution_Zurich_pm25  pollution_Zurich_so2  \n",
       "0                 3.000000              0.500000  \n",
       "1                 3.714286              0.885714  \n",
       "2                 2.571429              0.914286  \n",
       "3                 5.000000              0.785714  \n",
       "4                 1.285714              0.371429  \n",
       "..                     ...                   ...  \n",
       "123               1.714286              0.300000  \n",
       "124               1.857143              0.314286  \n",
       "125               1.000000              0.200000  \n",
       "126               1.571429              0.257143  \n",
       "127               1.142857              0.242857  \n",
       "\n",
       "[128 rows x 14 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:14 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:15 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:16 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:22:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:22:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:22:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit()\n",
    "\n",
    "l_index = []\n",
    "l_prophet = []\n",
    "l_prophet_multiva = []\n",
    "l_autoarima = []\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(df_train)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df_train.iloc[train_index]\n",
    "    test = df_train.iloc[test_index]\n",
    "    \n",
    "    l_prophet.extend(prophet_predictions(train, test))\n",
    "    l_prophet_multiva.extend(prophet_predictions_multiva(train, test))\n",
    "    l_autoarima.extend(autoarima_predictions(train, test))\n",
    "    \n",
    "    l_index.extend(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = pd.DataFrame()\n",
    "df_timeseries[\"ds\"] = df_train.iloc[l_index][\"ds\"]\n",
    "df_timeseries.index = l_index\n",
    "df_timeseries[\"prophet\"] = l_prophet\n",
    "df_timeseries[\"prophet_multiva\"] = l_prophet_multiva\n",
    "df_timeseries[\"autoarima\"] = l_autoarima\n",
    "df_timeseries[\"real_values\"] = df_train.iloc[l_index][\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of prophet: 33.96%\n",
      "MAPE of prophet_multiva: 52.61%\n",
      "MAPE of autoarima: 27.85%\n",
      "MAPE of real_values: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for e in df_timeseries.columns[1:]:\n",
    "    mape=calculate_mape(df_timeseries[\"real_values\"],df_timeseries[e])\n",
    "    print(f'MAPE of {e}: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:52:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:07 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:52:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:08 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:52:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:52:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:52:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE of prophet: 47.53%\n",
      "MAPE of prophet_multiva: 49.66%\n",
      "MAPE of autoarima: 27.08%\n",
      "MAPE of real_values: 0.00%\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "l_index = []\n",
    "l_prophet = []\n",
    "l_prophet_multiva = []\n",
    "l_autoarima = []\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(df_train)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df_train.iloc[train_index]\n",
    "    test = df_train.iloc[test_index]\n",
    "    \n",
    "    l_prophet.extend(prophet_predictions(train, test))\n",
    "    l_prophet_multiva.extend(prophet_predictions_multiva(train, test))\n",
    "    l_autoarima.extend(autoarima_predictions(train, test))\n",
    "    \n",
    "    l_index.extend(test_index)\n",
    "\n",
    "df_timeseries = pd.DataFrame()\n",
    "df_timeseries[\"ds\"] = df_train.iloc[l_index][\"ds\"]\n",
    "df_timeseries.index = l_index\n",
    "df_timeseries[\"prophet\"] = l_prophet\n",
    "df_timeseries[\"prophet_multiva\"] = l_prophet_multiva\n",
    "df_timeseries[\"autoarima\"] = l_autoarima\n",
    "df_timeseries[\"real_values\"] = df_train.iloc[l_index][\"y\"]\n",
    "\n",
    "for e in df_timeseries.columns[1:]:\n",
    "    mape=calculate_mape(df_timeseries[\"real_values\"],df_timeseries[e])\n",
    "    print(f'MAPE of {e}: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
